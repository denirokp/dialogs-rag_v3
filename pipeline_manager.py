#!/usr/bin/env python3
"""
Pipeline Manager - Ð¦ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð²ÑÐµÐ¼Ð¸ ÑÑ‚Ð°Ð¿Ð°Ð¼Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
"""

import sys
import json
import logging
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional, Callable
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð°Ð¿ÐºÑƒ pipeline Ð² Ð¿ÑƒÑ‚ÑŒ
pipeline_path = str(Path(__file__).parent / "pipeline")
if pipeline_path not in sys.path:
    sys.path.append(pipeline_path)

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/pipeline_manager.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹ pipeline
try:
    from stage1_detect_delivery import main as stage1_main
    from stage1_5_sample_filter import main as stage1_5_main
    from stage2_extract_entities import main as stage2_main
    from stage3_normalize import main as stage3_main
    from stage4_cluster import main as stage4_main
    from stage5_aggregate import main as stage5_main
    from stage6_report import main as stage6_main
    from stage7_quality import main as stage7_main
except ImportError as e:
    logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹ pipeline: {e}")
    logger.error("ðŸ’¡ Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð²ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹ pipeline Ð½Ð°Ñ…Ð¾Ð´ÑÑ‚ÑÑ Ð² Ð¿Ð°Ð¿ÐºÐµ pipeline/")
    sys.exit(1)

class StageStatus(Enum):
    """Ð¡Ñ‚Ð°Ñ‚ÑƒÑÑ‹ ÑÑ‚Ð°Ð¿Ð¾Ð²"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

@dataclass
class StageResult:
    """Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ð¿Ð°"""
    stage_id: str
    stage_name: str
    status: StageStatus
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    duration_seconds: Optional[float] = None
    error_message: Optional[str] = None
    output_files: List[str] = None
    metrics: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.output_files is None:
            self.output_files = []
        if self.metrics is None:
            self.metrics = {}

@dataclass
class PipelineConfig:
    """ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ pipeline"""
    input_file: str = "data/dialogs.xlsx"
    output_dir: str = "artifacts"
    reports_dir: str = "reports"
    logs_dir: str = "logs"
    batch_size: int = 100
    max_retries: int = 3
    parallel_execution: bool = False
    skip_failed_stages: bool = False
    cleanup_intermediate: bool = False

class PipelineManager:
    """Ð¦ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ pipeline"""
    
    def __init__(self, config: PipelineConfig = None):
        self.config = config or PipelineConfig()
        self.stages = self._initialize_stages()
        self.results: Dict[str, StageResult] = {}
        self.pipeline_start_time: Optional[datetime] = None
        self.pipeline_end_time: Optional[datetime] = None
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸
        self._create_directories()
    
    def _initialize_stages(self) -> Dict[str, Dict[str, Any]]:
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÑ‚Ð°Ð¿Ð¾Ð² pipeline"""
        return {
            "1": {
                "name": "Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸",
                "function": stage1_main,
                "dependencies": [],
                "output_files": ["stage1_delivery.jsonl"],
                "description": "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð², Ð³Ð´Ðµ Ð¾Ð±ÑÑƒÐ¶Ð´Ð°ÐµÑ‚ÑÑ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ°"
            },
            "1.5": {
                "name": "Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð¾Ð²",
                "function": stage1_5_main,
                "dependencies": ["1"],
                "output_files": ["stage1_5_sampling.jsonl"],
                "description": "Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð½Ð¾ÑÑ‚Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð² Ñ Ð¾Ð±Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼ ÑÐºÐ¾Ñ€Ð¸Ð½Ð³Ð¾Ð¼"
            },
            "2": {
                "name": "Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÐµÐ¹", 
                "function": stage2_main,
                "dependencies": ["1"],
                "output_files": ["stage2_extracted.jsonl"],
                "description": "Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð±Ð°Ñ€ÑŒÐµÑ€Ð¾Ð², Ð¸Ð´ÐµÐ¹ Ð¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² Ð¸Ð· Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²"
            },
            "3": {
                "name": "ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð¾Ðº",
                "function": stage3_main,
                "dependencies": ["2"],
                "output_files": ["stage3_normalized.jsonl"],
                "description": "ÐŸÑ€Ð¸Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð¾Ðº Ðº ÐµÐ´Ð¸Ð½Ð¾Ð¼Ñƒ Ð²Ð¸Ð´Ñƒ"
            },
            "4": {
                "name": "ÐšÐ»Ð°ÑÑ‚ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ñ",
                "function": stage4_main,
                "dependencies": ["3"],
                "output_files": ["stage4_clusters.json"],
                "description": "Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ñ… Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð¾Ðº Ð² ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ñ‹"
            },
            "5": {
                "name": "ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº",
                "function": stage5_main,
                "dependencies": ["4"],
                "output_files": ["aggregate_results.json", "barriers.csv", "ideas.csv", "signals.csv"],
                "description": "Ð Ð°ÑÑ‡ÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¸ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¿Ð¾ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð°Ð¼"
            },
            "6": {
                "name": "Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²",
                "function": stage6_main,
                "dependencies": ["5"],
                "output_files": ["report.md", "report.xlsx", "appendix_ids.md"],
                "description": "Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð² Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¹"
            },
            "7": {
                "name": "ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°",
                "function": stage7_main,
                "dependencies": ["6"],
                "output_files": ["quality.json"],
                "description": "Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"
            }
        }
    
    def _create_directories(self):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ñ… Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹"""
        directories = [
            self.config.output_dir,
            self.config.reports_dir,
            self.config.logs_dir
        ]
        
        for directory in directories:
            Path(directory).mkdir(exist_ok=True)
            logger.info(f"ðŸ“ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð° Ð¿Ð°Ð¿ÐºÐ°: {directory}")
    
    def get_stage_status(self, stage_id: str) -> StageStatus:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° ÑÑ‚Ð°Ð¿Ð°"""
        if stage_id not in self.results:
            return StageStatus.PENDING
        return self.results[stage_id].status
    
    def can_run_stage(self, stage_id: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐ° ÑÑ‚Ð°Ð¿Ð°"""
        if stage_id not in self.stages:
            return False
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸
        for dep in self.stages[stage_id]["dependencies"]:
            if self.get_stage_status(dep) != StageStatus.COMPLETED:
                return False
        
        return True
    
    def run_stage(self, stage_id: str) -> StageResult:
        """Ð—Ð°Ð¿ÑƒÑÐº ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ ÑÑ‚Ð°Ð¿Ð°"""
        if stage_id not in self.stages:
            raise ValueError(f"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÑÑ‚Ð°Ð¿: {stage_id}")
        
        stage_info = self.stages[stage_id]
        stage_name = stage_info["name"]
        
        logger.info(f"ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº ÑÑ‚Ð°Ð¿Ð° {stage_id}: {stage_name}")
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
        result = StageResult(
            stage_id=stage_id,
            stage_name=stage_name,
            status=StageStatus.RUNNING,
            start_time=datetime.now()
        )
        
        self.results[stage_id] = result
        
        try:
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸
            if not self.can_run_stage(stage_id):
                missing_deps = [
                    dep for dep in stage_info["dependencies"]
                    if self.get_stage_status(dep) != StageStatus.COMPLETED
                ]
                raise ValueError(f"ÐÐµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ñ‹ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸: {missing_deps}")
            
            # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÑ‚Ð°Ð¿
            stage_info["function"]()
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
            result.status = StageStatus.COMPLETED
            result.end_time = datetime.now()
            result.duration_seconds = (result.end_time - result.start_time).total_seconds()
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
            self._check_output_files(stage_id, result)
            
            logger.info(f"âœ… Ð­Ñ‚Ð°Ð¿ {stage_id} Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð° {result.duration_seconds:.1f}Ñ")
            
        except Exception as e:
            result.status = StageStatus.FAILED
            result.end_time = datetime.now()
            result.duration_seconds = (result.end_time - result.start_time).total_seconds()
            result.error_message = str(e)
            
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² ÑÑ‚Ð°Ð¿Ðµ {stage_id}: {e}")
            
            if not self.config.skip_failed_stages:
                raise
        
        return result
    
    def _check_output_files(self, stage_id: str, result: StageResult):
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² ÑÑ‚Ð°Ð¿Ð°"""
        expected_files = self.stages[stage_id]["output_files"]
        
        for filename in expected_files:
            file_path = Path(self.config.output_dir) / filename
            if file_path.exists():
                result.output_files.append(str(file_path))
            else:
                logger.warning(f"âš ï¸ ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {file_path}")
    
    def run_pipeline(self, stage_ids: List[str] = None) -> Dict[str, StageResult]:
        """Ð—Ð°Ð¿ÑƒÑÐº pipeline"""
        if stage_ids is None:
            stage_ids = list(self.stages.keys())
        
        logger.info("ðŸ” Dialogs RAG - Pipeline Manager")
        logger.info("=" * 60)
        
        self.pipeline_start_time = datetime.now()
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸
        if not self._check_dependencies():
            raise RuntimeError("ÐÐµ Ð²ÑÐµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹")
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÑ‚Ð°Ð¿Ñ‹
        for stage_id in stage_ids:
            try:
                self.run_stage(stage_id)
            except Exception as e:
                logger.error(f"âŒ Pipeline Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð½Ð° ÑÑ‚Ð°Ð¿Ðµ {stage_id}: {e}")
                if not self.config.skip_failed_stages:
                    break
        
        self.pipeline_end_time = datetime.now()
        
        # Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
        self._log_pipeline_summary()
        
        return self.results
    
    def _check_dependencies(self) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹"""
        logger.info("ðŸ” ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹...")
        
        try:
            import pandas
            import openpyxl
            import tqdm
            import tenacity
            import sklearn
            import numpy
            import openai
            import chromadb
            import sentence_transformers
            logger.info("âœ… Ð’ÑÐµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹")
            return True
        except ImportError as e:
            logger.error(f"âŒ ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ: {e}")
            logger.error("ðŸ’¡ Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸: pip install -r requirements.txt")
            return False
    
    def _log_pipeline_summary(self):
        """Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸"""
        total_stages = len(self.results)
        completed_stages = sum(1 for r in self.results.values() if r.status == StageStatus.COMPLETED)
        failed_stages = sum(1 for r in self.results.values() if r.status == StageStatus.FAILED)
        
        total_duration = (self.pipeline_end_time - self.pipeline_start_time).total_seconds()
        
        logger.info("=" * 60)
        logger.info(f"ðŸ“Š Pipeline Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½: {completed_stages}/{total_stages} ÑÑ‚Ð°Ð¿Ð¾Ð² ÑƒÑÐ¿ÐµÑˆÐ½Ð¾")
        logger.info(f"â±ï¸ ÐžÐ±Ñ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ: {total_duration:.1f} ÑÐµÐº")
        
        if failed_stages > 0:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±Ð¾Ðº: {failed_stages}")
            for stage_id, result in self.results.items():
                if result.status == StageStatus.FAILED:
                    logger.error(f"  - Ð­Ñ‚Ð°Ð¿ {stage_id}: {result.error_message}")
        else:
            logger.info("ðŸŽ‰ Ð’ÑÐµ ÑÑ‚Ð°Ð¿Ñ‹ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ñ‹ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!")
            logger.info("ðŸ“ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² Ð¿Ð°Ð¿ÐºÐ°Ñ… artifacts/ Ð¸ reports/")
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° pipeline"""
        return {
            "pipeline_start_time": self.pipeline_start_time.isoformat() if self.pipeline_start_time else None,
            "pipeline_end_time": self.pipeline_end_time.isoformat() if self.pipeline_end_time else None,
            "total_duration_seconds": (self.pipeline_end_time - self.pipeline_start_time).total_seconds() if self.pipeline_start_time and self.pipeline_end_time else None,
            "stages": {
                stage_id: {
                    "name": result.stage_name,
                    "status": result.status.value,
                    "duration_seconds": result.duration_seconds,
                    "error_message": result.error_message,
                    "output_files": result.output_files
                }
                for stage_id, result in self.results.items()
            }
        }
    
    def save_pipeline_state(self, filepath: str = None):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ pipeline"""
        if filepath is None:
            filepath = Path(self.config.logs_dir) / f"pipeline_state_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        state = {
            "config": asdict(self.config),
            "pipeline_status": self.get_pipeline_status(),
            "timestamp": datetime.now().isoformat()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ðŸ’¾ Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ pipeline ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð² {filepath}")
    
    def load_pipeline_state(self, filepath: str):
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ pipeline"""
        with open(filepath, 'r', encoding='utf-8') as f:
            state = json.load(f)
        
        # Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ
        self.config = PipelineConfig(**state["config"])
        
        # Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÑ‚Ð°Ð¿Ð¾Ð²
        for stage_id, stage_data in state["pipeline_status"]["stages"].items():
            result = StageResult(
                stage_id=stage_id,
                stage_name=stage_data["name"],
                status=StageStatus(stage_data["status"]),
                duration_seconds=stage_data["duration_seconds"],
                error_message=stage_data["error_message"],
                output_files=stage_data["output_files"]
            )
            self.results[stage_id] = result
        
        logger.info(f"ðŸ“‚ Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ pipeline Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ð¸Ð· {filepath}")

def main():
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ CLI"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Pipeline Manager Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²")
    parser.add_argument(
        "--stages",
        nargs="+",
        choices=list("1234567") + ["1.5"] + ["all"],
        default=["all"],
        help="Ð­Ñ‚Ð°Ð¿Ñ‹ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ: all)"
    )
    parser.add_argument(
        "--from", 
        type=str,
        choices=list("123456") + ["1.5"],
        help="ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ñ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð³Ð¾ ÑÑ‚Ð°Ð¿Ð°"
    )
    parser.add_argument(
        "--to", 
        type=str,
        choices=list("123456") + ["1.5"],
        help="Ð—Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚ÑŒ Ð½Ð° ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð¼ ÑÑ‚Ð°Ð¿Ðµ"
    )
    parser.add_argument(
        "--config",
        type=str,
        help="ÐŸÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸"
    )
    parser.add_argument(
        "--skip-failed",
        action="store_true",
        help="ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÑŒ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ñ…"
    )
    
    args = parser.parse_args()
    
    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ð¿Ð¾Ð² Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ°
    all_stages = ["1", "1.5", "2", "3", "4", "5", "6", "7"]
    
    if "all" in args.stages:
        stages = all_stages
    else:
        stages = args.stages
    
    # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¿Ð¾ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ñƒ
    if hasattr(args, 'from_') and args.from_:
        from_idx = all_stages.index(args.from_)
        stages = [s for s in stages if all_stages.index(s) >= from_idx]
    
    if hasattr(args, 'to') and args.to:
        to_idx = all_stages.index(args.to)
        stages = [s for s in stages if all_stages.index(s) <= to_idx]
    
    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
    config = PipelineConfig()
    if args.skip_failed:
        config.skip_failed_stages = True
    
    # Ð—Ð°Ð¿ÑƒÑÐº pipeline
    manager = PipelineManager(config)
    success = manager.run_pipeline(stages)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
    manager.save_pipeline_state()
    
    if all(result.status == StageStatus.COMPLETED for result in success.values()):
        logger.info("ðŸŽ¯ Pipeline Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!")
        sys.exit(0)
    else:
        logger.error("ðŸ’¥ Pipeline Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ð¼Ð¸")
        sys.exit(1)

if __name__ == "__main__":
    main()
