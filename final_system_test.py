#!/usr/bin/env python3
"""
üéØ –§–ò–ù–ê–õ–¨–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï DoD –°–ò–°–¢–ï–ú–´
–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã
"""

import asyncio
import json
import logging
import sys
from pathlib import Path
from typing import Dict, List, Any
import pandas as pd
import numpy as np
import yaml
import jsonschema

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_taxonomy():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–∫—Å–æ–Ω–æ–º–∏–∏"""
    logger.info("üìã –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–∞–∫—Å–æ–Ω–æ–º–∏—é...")
    
    with open('taxonomy.yaml', 'r', encoding='utf-8') as f:
        taxonomy = yaml.safe_load(f)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    assert 'themes' in taxonomy, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'themes'"
    assert 'limits' in taxonomy, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'limits'"
    
    themes = taxonomy['themes']
    assert len(themes) > 0, "–ù–µ—Ç —Ç–µ–º –≤ —Ç–∞–∫—Å–æ–Ω–æ–º–∏–∏"
    
    total_subthemes = 0
    for theme in themes:
        assert 'id' in theme, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç id –≤ —Ç–µ–º–µ {theme}"
        assert 'name' in theme, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç name –≤ —Ç–µ–º–µ {theme}"
        assert 'subthemes' in theme, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç subthemes –≤ —Ç–µ–º–µ {theme}"
        
        for subtheme in theme['subthemes']:
            assert 'id' in subtheme, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç id –≤ –ø–æ–¥—Ç–µ–º–µ {subtheme}"
            assert 'name' in subtheme, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç name –≤ –ø–æ–¥—Ç–µ–º–µ {subtheme}"
            total_subthemes += 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –ø–æ–¥—Ç–µ–º
    max_subthemes = taxonomy['limits']['max_subthemes']
    assert total_subthemes <= max_subthemes, f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –ø–æ–¥—Ç–µ–º: {total_subthemes} > {max_subthemes}"
    
    logger.info(f"‚úÖ –¢–∞–∫—Å–æ–Ω–æ–º–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞: {len(themes)} —Ç–µ–º, {total_subthemes} –ø–æ–¥—Ç–µ–º")
    return taxonomy

def test_schema():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ JSON —Å—Ö–µ–º—ã"""
    logger.info("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º JSON —Å—Ö–µ–º—É...")
    
    with open('schemas/mentions.schema.json', 'r', encoding='utf-8') as f:
        schema = json.load(f)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ö–µ–º—ã
    assert 'type' in schema, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç type –≤ —Å—Ö–µ–º–µ"
    assert 'properties' in schema, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç properties –≤ —Å—Ö–µ–º–µ"
    assert 'required' in schema, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç required –≤ —Å—Ö–µ–º–µ"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
    required_fields = schema['required']
    expected_fields = ['dialog_id', 'turn_id', 'theme', 'subtheme', 'label_type', 'text_quote', 'confidence']
    for field in expected_fields:
        assert field in required_fields, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ {field}"
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
    valid_mention = {
        "dialog_id": 1,
        "turn_id": 0,
        "theme": "–¥–æ—Å—Ç–∞–≤–∫–∞",
        "subtheme": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ",
        "label_type": "–±–∞—Ä—å–µ—Ä",
        "text_quote": "–£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π",
        "delivery_type": "complaint",
        "cause_hint": "–ø—Ä–∏—á–∏–Ω–∞ —É–∫–∞–∑–∞–Ω–∞",
        "confidence": 0.95
    }
    
    try:
        jsonschema.validate(valid_mention, schema)
        logger.info("‚úÖ –í–∞–ª–∏–¥–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø—Ä–æ—à–ª–æ –ø—Ä–æ–≤–µ—Ä–∫—É —Å—Ö–µ–º—ã")
    except jsonschema.ValidationError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ
    invalid_mention = {
        "dialog_id": 1,
        "turn_id": 0,
        "theme": "–¥–æ—Å—Ç–∞–≤–∫–∞",
        "subtheme": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ",
        "label_type": "–±–∞—Ä—å–µ—Ä",
        "text_quote": "",  # –ü—É—Å—Ç–∞—è —Ü–∏—Ç–∞—Ç–∞
        "confidence": 0.95
    }
    
    try:
        jsonschema.validate(invalid_mention, schema)
        logger.error("‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø—Ä–æ—à–ª–æ –ø—Ä–æ–≤–µ—Ä–∫—É")
        raise AssertionError("–ù–µ–≤–∞–ª–∏–¥–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã–ª–æ –±—ã—Ç—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ")
    except jsonschema.ValidationError:
        logger.info("‚úÖ –ù–µ–≤–∞–ª–∏–¥–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ")
    
    logger.info("‚úÖ JSON —Å—Ö–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    return schema

def test_dedup_script():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
    logger.info("üîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∫—Ä–∏–ø—Ç –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
    test_mentions = [
        {
            "dialog_id": 1,
            "turn_id": 0,
            "theme": "–¥–æ—Å—Ç–∞–≤–∫–∞",
            "subtheme": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ",
            "label_type": "–±–∞—Ä—å–µ—Ä",
            "text_quote": "–£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π",
            "confidence": 0.95
        },
        {
            "dialog_id": 1,
            "turn_id": 1,
            "theme": "–¥–æ—Å—Ç–∞–≤–∫–∞",
            "subtheme": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ",
            "label_type": "–±–∞—Ä—å–µ—Ä",
            "text_quote": "–£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π",  # –î—É–±–ª–∏–∫–∞—Ç
            "confidence": 0.90
        },
        {
            "dialog_id": 2,
            "turn_id": 0,
            "theme": "–¥–æ—Å—Ç–∞–≤–∫–∞",
            "subtheme": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ",
            "label_type": "–±–∞—Ä—å–µ—Ä",
            "text_quote": "–î—Ä—É–≥–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π",  # –ù–µ –¥—É–±–ª–∏–∫–∞—Ç
            "confidence": 0.85
        }
    ]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    temp_file = "artifacts/temp_test_mentions.jsonl"
    Path("artifacts").mkdir(exist_ok=True)
    
    with open(temp_file, 'w', encoding='utf-8') as f:
        for mention in test_mentions:
            f.write(json.dumps(mention, ensure_ascii=False) + '\n')
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é
    import subprocess
    result = subprocess.run([
        'python', 'scripts/dedup.py', 
        '--in', temp_file, 
        '--out', 'artifacts/test_dedup_output.jsonl'
    ], capture_output=True, text=True)
    
    if result.returncode != 0:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {result.stderr}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    deduped_mentions = []
    with open('artifacts/test_dedup_output.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            deduped_mentions.append(json.loads(line))
    
    # –î–æ–ª–∂–Ω–æ –æ—Å—Ç–∞—Ç—å—Å—è 2 —É–ø–æ–º–∏–Ω–∞–Ω–∏—è (—É–±—Ä–∞–ª–∏ 1 –¥—É–±–ª–∏–∫–∞—Ç)
    assert len(deduped_mentions) == 2, f"–û–∂–∏–¥–∞–ª–æ—Å—å 2 —É–ø–æ–º–∏–Ω–∞–Ω–∏—è, –ø–æ–ª—É—á–µ–Ω–æ {len(deduped_mentions)}"
    
    # –û—á–∏—Å—Ç–∫–∞
    Path(temp_file).unlink(missing_ok=True)
    Path('artifacts/test_dedup_output.jsonl').unlink(missing_ok=True)
    
    logger.info("‚úÖ –°–∫—Ä–∏–ø—Ç –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    return True

def test_quality_checks():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
    logger.info("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_mentions = [
        {
            "dialog_id": 1,
            "turn_id": 0,
            "theme": "–¥–æ—Å—Ç–∞–≤–∫–∞",
            "subtheme": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ",
            "label_type": "–±–∞—Ä—å–µ—Ä",
            "text_quote": "–£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π",
            "confidence": 0.95
        },
        {
            "dialog_id": 2,
            "turn_id": 0,
            "theme": "–ø—Ä–æ—á–µ–µ",
            "subtheme": "–¥—Ä—É–≥–æ–µ",
            "label_type": "–±–∞—Ä—å–µ—Ä",
            "text_quote": "–ö–∞–∫–∞—è-—Ç–æ –¥—Ä—É–≥–∞—è –ø—Ä–æ–±–ª–µ–º–∞",
            "confidence": 0.60
        }
    ]
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã –≤ DuckDB
    import duckdb
    
    conn = duckdb.connect(':memory:')
    
    # –¢–∞–±–ª–∏—Ü–∞ –¥–∏–∞–ª–æ–≥–æ–≤
    dialog_ids = list(set(m['dialog_id'] for m in test_mentions))
    dialogs_df = pd.DataFrame({'dialog_id': dialog_ids})
    conn.register('dialogs', dialogs_df)
    
    # –¢–∞–±–ª–∏—Ü–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
    mentions_df = pd.DataFrame(test_mentions)
    conn.register('mentions', mentions_df)
    
    # –¢–∞–±–ª–∏—Ü–∞ utterances (–≤—Å–µ –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞)
    utterances_data = []
    for mention in test_mentions:
        utterances_data.append({
            'dialog_id': mention['dialog_id'],
            'turn_id': mention['turn_id'],
            'role': 'client'
        })
    utterances_df = pd.DataFrame(utterances_data)
    conn.register('utterances', utterances_df)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
    results = {}
    
    # Q1: Evidence-100 (–ø—É—Å—Ç—ã–µ —Ü–∏—Ç–∞—Ç—ã)
    empty_quotes = conn.execute("SELECT COUNT(*) FROM mentions WHERE text_quote IS NULL OR LENGTH(TRIM(text_quote)) = 0").fetchone()[0]
    results['empty_quotes'] = empty_quotes
    
    # Q2: Client-only-100 (–Ω–µ –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è)
    non_client = conn.execute("SELECT COUNT(*) FROM mentions m LEFT JOIN utterances u USING (dialog_id, turn_id) WHERE u.role <> 'client'").fetchone()[0]
    results['non_client_mentions'] = non_client
    
    # Q4: Coverage (–¥–æ–ª—è "–ø—Ä–æ—á–µ–µ")
    misc_share = conn.execute("SELECT ROUND(100.0 * COUNT(*) FILTER (WHERE theme='–ø—Ä–æ—á–µ–µ') / COUNT(*), 2) FROM mentions").fetchone()[0]
    results['misc_share_pct'] = misc_share
    
    conn.close()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    assert results.get('empty_quotes', 0) == 0, "–ù–∞–π–¥–µ–Ω—ã –ø—É—Å—Ç—ã–µ —Ü–∏—Ç–∞—Ç—ã"
    assert results.get('non_client_mentions', 0) == 0, "–ù–∞–π–¥–µ–Ω—ã —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –Ω–µ –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞"
    
    logger.info(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç–∞—é—Ç: {results}")
    return results

def test_sql_summaries():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SQL —Å–≤–æ–¥–æ–∫"""
    logger.info("üìä –¢–µ—Å—Ç–∏—Ä—É–µ–º SQL —Å–≤–æ–¥–∫–∏...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_mentions = [
        {
            "dialog_id": 1,
            "turn_id": 0,
            "theme": "–¥–æ—Å—Ç–∞–≤–∫–∞",
            "subtheme": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ",
            "label_type": "–±–∞—Ä—å–µ—Ä",
            "text_quote": "–£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π",
            "confidence": 0.95
        },
        {
            "dialog_id": 2,
            "turn_id": 0,
            "theme": "–¥–æ—Å—Ç–∞–≤–∫–∞",
            "subtheme": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ",
            "label_type": "–±–∞—Ä—å–µ—Ä",
            "text_quote": "–î—Ä—É–≥–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π",
            "confidence": 0.85
        },
        {
            "dialog_id": 3,
            "turn_id": 0,
            "theme": "–ø—Ä–æ–¥—É–∫—Ç",
            "subtheme": "—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –Ω–µ –ø–æ–Ω—è—Ç–µ–Ω",
            "label_type": "–±–∞—Ä—å–µ—Ä",
            "text_quote": "–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –Ω–µ –ø–æ–Ω—è—Ç–µ–Ω",
            "confidence": 0.90
        }
    ]
    
    import duckdb
    
    conn = duckdb.connect(':memory:')
    
    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
    dialog_ids = list(set(m['dialog_id'] for m in test_mentions))
    dialogs_df = pd.DataFrame({'dialog_id': dialog_ids})
    conn.register('dialogs', dialogs_df)
    
    mentions_df = pd.DataFrame(test_mentions)
    conn.register('mentions', mentions_df)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ SQL –∑–∞–ø—Ä–æ—Å—ã
    summaries = {}
    
    # –°–≤–æ–¥–∫–∞ –ø–æ —Ç–µ–º–∞–º
    themes_result = conn.execute("""
        SELECT theme,
               COUNT(DISTINCT dialog_id) AS dialog_count,
               COUNT(*) AS mention_count,
               ROUND(100.0 * COUNT(DISTINCT dialog_id) / (SELECT COUNT(*) FROM dialogs), 1) AS share_of_dialogs_pct
        FROM mentions
        GROUP BY theme
        ORDER BY dialog_count DESC
    """).fetchdf()
    summaries['summary_themes'] = themes_result.to_dict('records')
    
    # –°–≤–æ–¥–∫–∞ –ø–æ –ø–æ–¥—Ç–µ–º–∞–º
    subthemes_result = conn.execute("""
        SELECT theme, subtheme,
               COUNT(DISTINCT dialog_id) AS dialog_count,
               COUNT(*) AS mention_count,
               ROUND(100.0 * COUNT(DISTINCT dialog_id) / (SELECT COUNT(*) FROM dialogs), 1) AS share_of_dialogs_pct
        FROM mentions
        GROUP BY theme, subtheme
        ORDER BY dialog_count DESC
    """).fetchdf()
    summaries['summary_subthemes'] = subthemes_result.to_dict('records')
    
    # –ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∞—Ç
    quotes_result = conn.execute("""
        SELECT theme, subtheme, dialog_id, turn_id, text_quote
        FROM mentions
    """).fetchdf()
    summaries['index_quotes'] = quotes_result.to_dict('records')
    
    conn.close()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    assert 'summary_themes' in summaries, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ç–∞–±–ª–∏—Ü–∞ summary_themes"
    assert 'summary_subthemes' in summaries, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ç–∞–±–ª–∏—Ü–∞ summary_subthemes"
    assert 'index_quotes' in summaries, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ç–∞–±–ª–∏—Ü–∞ index_quotes"
    
    themes_summary = summaries['summary_themes']
    assert len(themes_summary) > 0, "–ü—É—Å—Ç–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ —Ç–µ–º–∞–º"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–º–∞ "–¥–æ—Å—Ç–∞–≤–∫–∞" –µ—Å—Ç—å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
    delivery_theme = next((t for t in themes_summary if t['theme'] == '–¥–æ—Å—Ç–∞–≤–∫–∞'), None)
    assert delivery_theme is not None, "–¢–µ–º–∞ '–¥–æ—Å—Ç–∞–≤–∫–∞' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Å–≤–æ–¥–∫–µ"
    assert delivery_theme['dialog_count'] == 2, f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è —Ç–µ–º—ã '–¥–æ—Å—Ç–∞–≤–∫–∞': {delivery_theme['dialog_count']}"
    
    logger.info(f"‚úÖ SQL —Å–≤–æ–¥–∫–∏ —Ä–∞–±–æ—Ç–∞—é—Ç: {len(summaries)} —Ç–∞–±–ª–∏—Ü —Å–æ–∑–¥–∞–Ω–æ")
    return summaries

def test_jinja_templates():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Jinja —à–∞–±–ª–æ–Ω–æ–≤"""
    logger.info("üìù –¢–µ—Å—Ç–∏—Ä—É–µ–º Jinja —à–∞–±–ª–æ–Ω—ã...")
    
    from jinja2 import Environment, FileSystemLoader
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_data = {
        "total_dialogs": 100,
        "themes": [
            {"theme": "–¥–æ—Å—Ç–∞–≤–∫–∞", "dialog_count": 50, "mention_count": 75, "share_of_dialogs_pct": 50.0},
            {"theme": "–ø—Ä–æ–¥—É–∫—Ç", "dialog_count": 30, "mention_count": 45, "share_of_dialogs_pct": 30.0}
        ],
        "subthemes": [
            {"theme": "–¥–æ—Å—Ç–∞–≤–∫–∞", "subtheme": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ", "dialog_count": 25, "mention_count": 35, "share_of_dialogs_pct": 25.0}
        ]
    }
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω summary.jinja
    env = Environment(loader=FileSystemLoader('reports/templates'))
    template = env.get_template('summary.jinja')
    
    try:
        rendered = template.render(**test_data)
        assert "–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤: 100" in rendered, "–ù–µ–≤–µ—Ä–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∏–∞–ª–æ–≥–æ–≤"
        assert "–¥–æ—Å—Ç–∞–≤–∫–∞" in rendered, "–¢–µ–º–∞ '–¥–æ—Å—Ç–∞–≤–∫–∞' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ä–µ–Ω–¥–µ—Ä–µ"
        assert "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—ã–±–æ—Ä–æ—á–Ω–æ" in rendered, "–ü–æ–¥—Ç–µ–º–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ä–µ–Ω–¥–µ—Ä–µ"
        
        logger.info("‚úÖ –®–∞–±–ª–æ–Ω summary.jinja —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ —à–∞–±–ª–æ–Ω–∞: {e}")
        raise
    
    logger.info("‚úÖ Jinja —à–∞–±–ª–æ–Ω—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    return True

def test_makefile():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Makefile"""
    logger.info("üîß –¢–µ—Å—Ç–∏—Ä—É–µ–º Makefile...")
    
    makefile_path = Path('Makefile')
    assert makefile_path.exists(), "Makefile –Ω–µ –Ω–∞–π–¥–µ–Ω"
    
    with open(makefile_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ü–µ–ª–µ–π
    required_targets = ['extract', 'dedup', 'cluster', 'summaries', 'report', 'qa', 'eval', 'comprehensive', 'test']
    for target in required_targets:
        assert f"{target}:" in content, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ü–µ–ª—å {target} –≤ Makefile"
    
    logger.info("‚úÖ Makefile —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ü–µ–ª–∏")
    return True

def test_ci_workflow():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CI workflow"""
    logger.info("üîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º CI workflow...")
    
    workflow_path = Path('.github/workflows/qa.yml')
    assert workflow_path.exists(), "CI workflow –Ω–µ –Ω–∞–π–¥–µ–Ω"
    
    with open(workflow_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã workflow
    assert 'name: DoD QA' in content, "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è workflow"
    assert 'on: [push, pull_request]' in content, "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã"
    assert 'make qa' in content, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–º–∞–Ω–¥–∞ make qa"
    assert 'make eval' in content, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–º–∞–Ω–¥–∞ make eval"
    
    logger.info("‚úÖ CI workflow –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    return True

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ DoD —Å–∏—Å—Ç–µ–º—ã...")
    
    try:
        # –¢–µ—Å—Ç —Ç–∞–∫—Å–æ–Ω–æ–º–∏–∏
        taxonomy = test_taxonomy()
        
        # –¢–µ—Å—Ç JSON —Å—Ö–µ–º—ã
        schema = test_schema()
        
        # –¢–µ—Å—Ç –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        test_dedup_script()
        
        # –¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_results = test_quality_checks()
        
        # –¢–µ—Å—Ç SQL —Å–≤–æ–¥–æ–∫
        summaries = test_sql_summaries()
        
        # –¢–µ—Å—Ç Jinja —à–∞–±–ª–æ–Ω–æ–≤
        test_jinja_templates()
        
        # –¢–µ—Å—Ç Makefile
        test_makefile()
        
        # –¢–µ—Å—Ç CI workflow
        test_ci_workflow()
        
        # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\n" + "="*70)
        print("üéØ –ò–¢–û–ì–ò –§–ò–ù–ê–õ–¨–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø DoD –°–ò–°–¢–ï–ú–´")
        print("="*70)
        print(f"‚úÖ –¢–∞–∫—Å–æ–Ω–æ–º–∏—è: {len(taxonomy['themes'])} —Ç–µ–º, {sum(len(t['subthemes']) for t in taxonomy['themes'])} –ø–æ–¥—Ç–µ–º")
        print(f"‚úÖ JSON —Å—Ö–µ–º–∞: –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print(f"‚úÖ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: —Å–∫—Ä–∏–ø—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞: {quality_results}")
        print(f"‚úÖ SQL —Å–≤–æ–¥–∫–∏: {len(summaries)} —Ç–∞–±–ª–∏—Ü —Å–æ–∑–¥–∞–Ω–æ")
        print(f"‚úÖ Jinja —à–∞–±–ª–æ–Ω—ã: —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print(f"‚úÖ Makefile: –≤—Å–µ —Ü–µ–ª–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        print(f"‚úÖ CI workflow: –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print("="*70)
        print("üéâ –í–°–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ DoD –°–ò–°–¢–ï–ú–´ –†–ê–ë–û–¢–ê–Æ–¢ –ö–û–†–†–ï–ö–¢–ù–û!")
        print("="*70)
        
        logger.info("üéâ –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        raise

if __name__ == "__main__":
    main()
