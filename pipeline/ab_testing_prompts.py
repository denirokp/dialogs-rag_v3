#!/usr/bin/env python3
"""
A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –ø—Ä–æ–º–ø—Ç–æ–≤
"""

import json
import logging
import pandas as pd
import random
from pathlib import Path
from typing import Dict, Any, List, Tuple
from collections import defaultdict
import statistics

import sys
sys.path.append(str(Path(__file__).parent.parent))

import openai
from config import settings

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –í–∞—Ä–∏–∞–Ω—Ç—ã –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
PROMPT_VARIANTS = {
    "baseline": "prompts/extract_entities.txt",
    "enhanced": "prompts/extract_entities_enhanced.txt",
    "minimal": "prompts/extract_entities_minimal.txt",
    "detailed": "prompts/extract_entities_detailed.txt"
}

def load_prompt_variant(variant_name: str) -> str:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø—Ä–æ–º–ø—Ç–∞"""
    
    prompt_file = PROMPT_VARIANTS.get(variant_name)
    if not prompt_file or not Path(prompt_file).exists():
        # Fallback –∫ –±–∞–∑–æ–≤–æ–º—É –ø—Ä–æ–º–ø—Ç—É
        prompt_file = "prompts/extract_entities.txt"
    
    return Path(prompt_file).read_text(encoding="utf-8")

def create_minimal_prompt() -> str:
    """–°–æ–∑–¥–∞–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
    
    return """
–†–æ–ª—å: –ê–Ω–∞–ª–∏—Ç–∏–∫ –¥–∏–∞–ª–æ–≥–æ–≤.

–ò–∑–≤–ª–µ–∫–∏ –∏–∑ –¥–∏–∞–ª–æ–≥–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç–∞–≤–∫–µ –≤ JSON:

1. –ë–ê–†–¨–ï–†–´: –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π
2. –ò–î–ï–ò: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞  
3. –°–ò–ì–ù–ê–õ–´: –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞

–§–æ—Ä–º–∞—Ç JSON:
{
  "delivery_related": true,
  "barriers": ["–ø—Ä–æ–±–ª–µ–º–∞1", "–ø—Ä–æ–±–ª–µ–º–∞2"],
  "ideas": ["–∏–¥–µ—è1"],
  "signals": ["—Å–∏–≥–Ω–∞–ª1"],
  "delivery_types": ["Avito –î–æ—Å—Ç–∞–≤–∫–∞"],
  "product_category": "—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞",
  "sentiment": "—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ"
}
"""

def create_detailed_prompt() -> str:
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞"""
    
    return """
–†–æ–ª—å: –≠–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∏–∞–ª–æ–≥–æ–≤ –ø–æ –¥–æ—Å—Ç–∞–≤–∫–µ —Å –≥–ª—É–±–æ–∫–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞ –∏ –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–¶–µ–ª—å: –ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ –∏ –∏–∑–≤–ª–µ—á—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è –ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã—Ö —Ä–µ—à–µ–Ω–∏–π.

–ê–ù–ê–õ–ò–ó–ò–†–£–ô –í–°–ï –†–ï–ü–õ–ò–ö–ò –ö–õ–ò–ï–ù–¢–ê —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø–æ–¥—Ç–µ–∫—Å—Ç–∞:

1. –ë–ê–†–¨–ï–†–´ (–ø—Ä–æ–±–ª–µ–º—ã –∫–ª–∏–µ–Ω—Ç–∞ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π):
   - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ: "–Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞", "–ø—Ä–æ–±–ª–µ–º—ã —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏", "—Å–±–æ–∏ —Å–∏—Å—Ç–µ–º—ã", "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"
   - –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ: "–≤—ã—Å–æ–∫–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Å–∫—Ä—ã—Ç—ã–µ –ø–ª–∞—Ç–µ–∂–∏", "–Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã", "–¥–æ—Ä–æ–≥–æ –¥–æ—Å—Ç–∞–≤–ª—è—Ç—å"
   - –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ: "–º–∞–ª–æ –ü–í–ó", "–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤ —Ä–µ–≥–∏–æ–Ω", "–¥–æ–ª–≥–∏–µ —Å—Ä–æ–∫–∏", "–ø–ª–æ—Ö–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞"
   - –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ: "–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞", "–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞", "–ø–æ—Ç–µ—Ä—è –ø–æ—Å—ã–ª–∫–∏", "–Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞"
   - –ü—Ä–æ—Ü–µ—Å—Å–Ω—ã–µ: "—Å–ª–æ–∂–Ω—ã–π –≤–æ–∑–≤—Ä–∞—Ç", "–ø–ª–æ—Ö–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è", "–Ω–µ—è—Å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è", "–Ω–µ—É–¥–æ–±–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å"

2. –ò–î–ï–ò (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞):
   - UX/UI: "–µ–¥–∏–Ω–∞—è –∫–Ω–æ–ø–∫–∞ –≤—ã–±–æ—Ä–∞", "—É–ø—Ä–æ—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å", "–¥–æ–±–∞–≤–∏—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫–∏", "—É–ª—É—á—à–∏—Ç—å –Ω–∞–≤–∏–≥–∞—Ü–∏—é"
   - –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ: "–ø—Ä–∏–º–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–∫—É–ø–∫–æ–π", "–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç", "—É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è", "–æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ"
   - –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ: "–±–æ–ª—å—à–µ –ü–í–ó", "—ç–∫—Å–ø—Ä–µ—Å—Å-–¥–æ—Å—Ç–∞–≤–∫–∞", "–≤—ã–±–æ—Ä –≤—Ä–µ–º–µ–Ω–∏", "–≥–∏–±–∫–∏–µ –æ–ø—Ü–∏–∏"
   - –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ: "—Å—É–±—Å–∏–¥–∏—Ä–æ–≤–∞–Ω–∏–µ", "—Å–∫–∏–¥–∫–∏ –∑–∞ –æ–±—ä–µ–º", "–±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞", "–ø—Ä–æ–∑—Ä–∞—á–Ω–æ–µ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"

3. –°–ò–ì–ù–ê–õ–´ (–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è):
   - –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è: "—Ç–æ–ª—å–∫–æ Avito –î–æ—Å—Ç–∞–≤–∫–∞", "–ª—é–±–ª—é —Å–∞–º–æ–≤—ã–≤–æ–∑", "–¥–æ–≤–µ—Ä—è—é –°–î–≠–ö", "–ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é –∫—É—Ä—å–µ—Ä–∞"
   - –ü–∞—Ç—Ç–µ—Ä–Ω—ã: "—á–∞—Å—Ç–æ –∑–∞–∫–∞–∑—ã–≤–∞—é", "—Ä–µ–¥–∫–æ –ø–æ–ª—å–∑—É—é—Å—å", "—Ç–æ–ª—å–∫–æ –¥–ª—è –¥–æ—Ä–æ–≥–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤", "—Å–µ–∑–æ–Ω–Ω—ã–µ –ø–æ–∫—É–ø–∫–∏"
   - –ú–æ—Ç–∏–≤–∞—Ü–∏–∏: "—Å–∫–æ—Ä–æ—Å—Ç—å –≤–∞–∂–Ω–µ–µ —Ü–µ–Ω—ã", "—Ü–µ–Ω–∞ –≤–∞–∂–Ω–µ–µ —Å–∫–æ—Ä–æ—Å—Ç–∏", "—É–¥–æ–±—Å—Ç–≤–æ –ø—Ä–µ–≤—ã—à–µ –≤—Å–µ–≥–æ", "–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å"

4. –ö–û–ù–¢–ï–ö–°–¢–ù–´–ô –ê–ù–ê–õ–ò–ó:
   - –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ, —Ñ—Ä—É—Å—Ç—Ä–∞—Ü–∏—è, —Å–æ–º–Ω–µ–Ω–∏–µ, –ø–æ–∑–∏—Ç–∏–≤, —ç–Ω—Ç—É–∑–∏–∞–∑–º, –±–µ–∑—Ä–∞–∑–ª–∏—á–∏–µ, —Ç—Ä–µ–≤–æ–≥–∞
   - –£—Ä–æ–≤–µ–Ω—å —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ—Å—Ç–∏: –Ω–æ–≤–∏—á–æ–∫, —Å—Ä–µ–¥–Ω–∏–π, —ç–∫—Å–ø–µ—Ä—Ç, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π
   - –°—Ä–æ—á–Ω–æ—Å—Ç—å: –∫—Ä–∏—Ç–∏—á–Ω–æ, –≤–∞–∂–Ω–æ, –Ω–µ–≤–∞–∂–Ω–æ, –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
   - –í–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–µ—à–µ–Ω–∏–µ: –±–ª–æ–∫–∏—Ä—É–µ—Ç –ø–æ–∫—É–ø–∫—É, –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—ã–±–æ—Ä, –Ω–µ –≤–ª–∏—è–µ—Ç, —É–ª—É—á—à–∞–µ—Ç –æ–ø—ã—Ç

5. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–ê–î–ê–ù–ù–´–ï:
   - –¢–∏–ø—ã –¥–æ—Å—Ç–∞–≤–∫–∏: Avito –î–æ—Å—Ç–∞–≤–∫–∞, –°–î–≠–ö, –Ø–Ω–¥–µ–∫—Å –î–æ—Å—Ç–∞–≤–∫–∞, –∫—É—Ä—å–µ—Ä—Å–∫–∞—è, —Å–∞–º–æ–≤—ã–≤–æ–∑, –ü–í–ó, –ü–æ—á—Ç–∞ –†–æ—Å—Å–∏–∏
   - –ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞: —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞, –º–µ–±–µ–ª—å, –æ–¥–µ–∂–¥–∞, —Å—Ç—Ä–æ–π–º–∞—Ç–µ—Ä–∏–∞–ª—ã, –ø—Ä–æ–¥—É–∫—Ç—ã, —Å–ø–æ—Ä—Ç, –¥—Ä—É–≥–æ–µ
   - –†–µ–≥–∏–æ–Ω: –ú–æ—Å–∫–≤–∞, –°–ü–±, —Ä–µ–≥–∏–æ–Ω—ã, —É–¥–∞–ª–µ–Ω–Ω—ã–µ
   - –°–µ–≥–º–µ–Ω—Ç –∫–ª–∏–µ–Ω—Ç–∞: —á–∞—Å—Ç–Ω—ã–π, –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π, –æ–ø—Ç–æ–≤—ã–π, B2B

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (—Å—Ç—Ä–æ–≥–æ JSON):
{
  "delivery_related": true,
  "barriers": [
    {
      "category": "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ",
      "text": "–Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ –¥–æ—Å—Ç–∞–≤–∫–∏",
      "severity": "–≤—ã—Å–æ–∫–∞—è",
      "context": "–∫–ª–∏–µ–Ω—Ç –Ω–µ –ø–æ–Ω–∏–º–∞–µ—Ç, –∫–∞–∫ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É",
      "impact": "–±–ª–æ–∫–∏—Ä—É–µ—Ç –ø–æ–∫—É–ø–∫—É"
    }
  ],
  "ideas": [
    {
      "category": "UX/UI", 
      "text": "–µ–¥–∏–Ω–∞—è –∫–Ω–æ–ø–∫–∞ –≤—ã–±–æ—Ä–∞ –¥–æ—Å—Ç–∞–≤–∫–∏",
      "feasibility": "–≤—ã—Å–æ–∫–∞—è",
      "impact": "—Å—Ä–µ–¥–Ω–∏–π",
      "user_value": "—É–ø—Ä–æ—â–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞"
    }
  ],
  "signals": [
    {
      "type": "–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è",
      "text": "–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ Avito –î–æ—Å—Ç–∞–≤–∫–∏",
      "confidence": "–≤—ã—Å–æ–∫–∞—è",
      "context": "–∫–ª–∏–µ–Ω—Ç —è–≤–Ω–æ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç —ç—Ç–æ—Ç —Å–µ—Ä–≤–∏—Å",
      "frequency": "—á–∞—Å—Ç–æ"
    }
  ],
  "emotional_state": "—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ",
  "expertise_level": "–Ω–æ–≤–∏—á–æ–∫", 
  "urgency": "–≤–∞–∂–Ω–æ",
  "decision_impact": "–±–ª–æ–∫–∏—Ä—É–µ—Ç –ø–æ–∫—É–ø–∫—É",
  "delivery_types": ["Avito –î–æ—Å—Ç–∞–≤–∫–∞"],
  "product_category": "—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞",
  "region": "–ú–æ—Å–∫–≤–∞",
  "segment": "—á–∞—Å—Ç–Ω—ã–π",
  "citations": [
    {
      "quote": "–ö–∞–∫ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –¥–æ—Å—Ç–∞–≤–∫—É?",
      "speaker": "–ö–ª–∏–µ–Ω—Ç",
      "context": "–≤–æ–ø—Ä–æ—Å –æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ",
      "timestamp": "00:01:30"
    }
  ],
  "confidence_score": 0.85,
  "extraction_notes": "–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –±–∞—Ä—å–µ—Ä–æ–≤"
}
"""

def extract_entities_with_prompt(dialog_text: str, dialog_id: str, prompt_variant: str) -> Dict[str, Any]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø—Ä–æ–º–ø—Ç–∞"""
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
        if prompt_variant == "minimal":
            prompt = create_minimal_prompt()
        elif prompt_variant == "detailed":
            prompt = create_detailed_prompt()
        else:
            prompt = load_prompt_variant(prompt_variant)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"–î–∏–∞–ª–æ–≥ ID: {dialog_id}\n\n{dialog_text}"}
        ]
        
        # –í—ã–∑—ã–≤–∞–µ–º API
        from openai import OpenAI
        client = OpenAI(api_key=settings.openai_api_key)
        
        response = client.chat.completions.create(
            model=settings.model_extract,
            messages=messages,
            temperature=0.1,
            max_tokens=2000
        )
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        content = response.choices[0].message.content.strip()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON
        import re
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if not json_match:
            raise ValueError("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
        
        extraction = json.loads(json_match.group())
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        extraction["dialog_id"] = dialog_id
        extraction["prompt_variant"] = prompt_variant
        extraction["extraction_timestamp"] = pd.Timestamp.now().isoformat()
        
        return extraction
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–ª—è –¥–∏–∞–ª–æ–≥–∞ {dialog_id} —Å –ø—Ä–æ–º–ø—Ç–æ–º {prompt_variant}: {e}")
        return {
            "dialog_id": dialog_id,
            "prompt_variant": prompt_variant,
            "delivery_related": False,
            "barriers": [],
            "ideas": [],
            "signals": [],
            "error": str(e)
        }

def evaluate_extraction_quality(extraction: Dict[str, Any]) -> Dict[str, float]:
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è"""
    
    quality_metrics = {
        "completeness": 0.0,
        "accuracy": 0.0,
        "consistency": 0.0,
        "overall_score": 0.0
    }
    
    # –ü–æ–ª–Ω–æ—Ç–∞ (completeness)
    has_barriers = len(extraction.get("barriers", [])) > 0
    has_ideas = len(extraction.get("ideas", [])) > 0
    has_signals = len(extraction.get("signals", [])) > 0
    has_metadata = bool(extraction.get("delivery_types") or extraction.get("product_category"))
    
    completeness = sum([has_barriers, has_ideas, has_signals, has_metadata]) / 4.0
    quality_metrics["completeness"] = completeness
    
    # –¢–æ—á–Ω–æ—Å—Ç—å (accuracy) - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
    accuracy_score = 0.0
    accuracy_checks = 0
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞—Ä—å–µ—Ä—ã
    barriers = extraction.get("barriers", [])
    if barriers:
        accuracy_checks += 1
        if all(isinstance(b, (str, dict)) for b in barriers):
            accuracy_score += 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–¥–µ–∏
    ideas = extraction.get("ideas", [])
    if ideas:
        accuracy_checks += 1
        if all(isinstance(i, (str, dict)) for i in ideas):
            accuracy_score += 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–≥–Ω–∞–ª—ã
    signals = extraction.get("signals", [])
    if signals:
        accuracy_checks += 1
        if all(isinstance(s, (str, dict)) for s in signals):
            accuracy_score += 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    if extraction.get("delivery_related") is not None:
        accuracy_checks += 1
        accuracy_score += 1
    
    quality_metrics["accuracy"] = accuracy_score / accuracy_checks if accuracy_checks > 0 else 0.0
    
    # –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (consistency) - –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –ª–æ–≥–∏–∫—É
    consistency_score = 1.0
    
    # –ï—Å–ª–∏ delivery_related = False, –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—É—â–Ω–æ—Å—Ç–µ–π
    if not extraction.get("delivery_related", True):
        if barriers or ideas or signals:
            consistency_score -= 0.5
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
    sentiment = extraction.get("sentiment", "")
    if sentiment and sentiment not in ["—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ", "—Å–æ–º–Ω–µ–Ω–∏–µ", "–ø–æ–∑–∏—Ç–∏–≤"]:
        consistency_score -= 0.2
    
    quality_metrics["consistency"] = max(0.0, consistency_score)
    
    # –û–±—â–∏–π –±–∞–ª–ª
    quality_metrics["overall_score"] = (
        quality_metrics["completeness"] * 0.4 +
        quality_metrics["accuracy"] * 0.4 +
        quality_metrics["consistency"] * 0.2
    )
    
    return quality_metrics

def run_ab_test(dialogs: List[Dict[str, Any]], 
                variants: List[str] = None,
                sample_size: int = 10) -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤"""
    
    logger.info("üß™ –ó–∞–ø—É—Å–∫ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤...")
    
    if variants is None:
        variants = list(PROMPT_VARIANTS.keys())
    
    # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç—ã –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    create_additional_prompts()
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É –¥–∏–∞–ª–æ–≥–æ–≤
    if len(dialogs) > sample_size:
        test_dialogs = random.sample(dialogs, sample_size)
    else:
        test_dialogs = dialogs
    
    logger.info(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º {len(test_dialogs)} –¥–∏–∞–ª–æ–≥–æ–≤ —Å {len(variants)} –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –ø—Ä–æ–º–ø—Ç–æ–≤")
    
    results = {}
    
    for variant in variants:
        logger.info(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–∞: {variant}")
        
        variant_results = []
        quality_scores = []
        
        for dialog in test_dialogs:
            dialog_id = dialog.get("dialog_id", f"dialog_{len(variant_results)}")
            dialog_text = dialog.get("text", "")
            
            if not dialog_text or len(dialog_text.strip()) < 10:
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–Ω–æ—Å—Ç–∏
            extraction = extract_entities_with_prompt(dialog_text, dialog_id, variant)
            variant_results.append(extraction)
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            quality = evaluate_extraction_quality(extraction)
            quality_scores.append(quality)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if quality_scores:
            avg_quality = {
                "completeness": statistics.mean([q["completeness"] for q in quality_scores]),
                "accuracy": statistics.mean([q["accuracy"] for q in quality_scores]),
                "consistency": statistics.mean([q["consistency"] for q in quality_scores]),
                "overall_score": statistics.mean([q["overall_score"] for q in quality_scores])
            }
        else:
            avg_quality = {"completeness": 0.0, "accuracy": 0.0, "consistency": 0.0, "overall_score": 0.0}
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_entities = sum(
            len(extraction.get("barriers", [])) + 
            len(extraction.get("ideas", [])) + 
            len(extraction.get("signals", []))
            for extraction in variant_results
        )
        
        successful_extractions = len([e for e in variant_results if not e.get("error")])
        
        results[variant] = {
            "total_dialogs": len(variant_results),
            "successful_extractions": successful_extractions,
            "success_rate": successful_extractions / len(variant_results) if variant_results else 0.0,
            "total_entities": total_entities,
            "avg_entities_per_dialog": total_entities / len(variant_results) if variant_results else 0.0,
            "quality_metrics": avg_quality,
            "extractions": variant_results
        }
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
    best_variant = max(results.keys(), key=lambda v: results[v]["quality_metrics"]["overall_score"])
    
    ab_test_results = {
        "test_metadata": {
            "total_dialogs": len(test_dialogs),
            "variants_tested": variants,
            "test_timestamp": pd.Timestamp.now().isoformat()
        },
        "results": results,
        "best_variant": best_variant,
        "recommendations": generate_ab_test_recommendations(results)
    }
    
    logger.info(f"‚úÖ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –õ—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç: {best_variant}")
    
    return ab_test_results

def create_additional_prompts():
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    minimal_prompt = create_minimal_prompt()
    Path("prompts/extract_entities_minimal.txt").write_text(minimal_prompt, encoding="utf-8")
    
    # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    detailed_prompt = create_detailed_prompt()
    Path("prompts/extract_entities_detailed.txt").write_text(detailed_prompt, encoding="utf-8")

def generate_ab_test_recommendations(results: Dict[str, Any]) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    recommendations = []
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    best_variant = max(results.keys(), key=lambda v: results[v]["quality_metrics"]["overall_score"])
    worst_variant = min(results.keys(), key=lambda v: results[v]["quality_metrics"]["overall_score"])
    
    best_score = results[best_variant]["quality_metrics"]["overall_score"]
    worst_score = results[worst_variant]["quality_metrics"]["overall_score"]
    
    recommendations.append(f"üèÜ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç '{best_variant}' (–±–∞–ª–ª: {best_score:.3f})")
    
    if best_score - worst_score > 0.2:
        recommendations.append(f"‚ö†Ô∏è –í–∞—Ä–∏–∞–Ω—Ç '{worst_variant}' –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ö—É–∂–µ (–±–∞–ª–ª: {worst_score:.3f})")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    for variant, data in results.items():
        quality = data["quality_metrics"]
        
        if quality["completeness"] < 0.7:
            recommendations.append(f"üìù –í–∞—Ä–∏–∞–Ω—Ç '{variant}' –∏–º–µ–µ—Ç –Ω–∏–∑–∫—É—é –ø–æ–ª–Ω–æ—Ç—É ({quality['completeness']:.3f})")
        
        if quality["accuracy"] < 0.8:
            recommendations.append(f"üéØ –í–∞—Ä–∏–∞–Ω—Ç '{variant}' –∏–º–µ–µ—Ç –Ω–∏–∑–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å ({quality['accuracy']:.3f})")
        
        if quality["consistency"] < 0.8:
            recommendations.append(f"üîÑ –í–∞—Ä–∏–∞–Ω—Ç '{variant}' –∏–º–µ–µ—Ç –Ω–∏–∑–∫—É—é —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å ({quality['consistency']:.3f})")
    
    return recommendations

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã stage1
    stage1_file = "artifacts/stage1_delivery.jsonl"
    if not Path(stage1_file).exists():
        logger.error(f"–§–∞–π–ª {stage1_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ Stage 1.")
        return
    
    # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã stage1
    delivery_dialogs = []
    with open(stage1_file, 'r', encoding='utf-8') as f:
        for line in f:
            data = json.loads(line.strip())
            if data.get('delivery_discussed', False):
                delivery_dialogs.append(data)
    
    if not delivery_dialogs:
        logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
    input_file = "data/dialogs.xlsx"
    df = pd.read_excel(input_file, engine='openpyxl')
    original_dialogs = df.to_dict('records')
    
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_dialogs = []
    for dialog_data in delivery_dialogs:
        dialog_id = dialog_data.get('dialog_id', 'unknown')
        
        # –ù–∞—Ö–æ–¥–∏–º –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∏–∞–ª–æ–≥ –ø–æ ID
        original_dialog = next((d for d in original_dialogs if str(d.get('ID –∑–≤–æ–Ω–∫–∞', '')) == dialog_id), None)
        if original_dialog:
            test_dialogs.append({
                'dialog_id': dialog_id,
                'text': original_dialog.get('–¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏', ''),
                'delivery_discussed': True
            })
    
    if not test_dialogs:
        logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º A/B —Ç–µ—Å—Ç
    ab_results = run_ab_test(test_dialogs, sample_size=5)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_file = "reports/ab_test_results.json"
    Path("reports").mkdir(exist_ok=True, parents=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(ab_results, f, ensure_ascii=False, indent=2)
    
    logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")

if __name__ == "__main__":
    main()
